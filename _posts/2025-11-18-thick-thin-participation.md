---
layout: post
title: "The thick and thin of public involvement"
author: Jeni Tennison
category: blog
featured: true
projects:
  - "Department for Education (DfE)"
topics:
  - Public sector
---

> “I want to offer another vision of human compatibility in AI: one that embraces a thick and demanding world of human capacity, social complexity, and local politics in place of the thin, pliable, universalizing world of individual preferences.”
> 
> [Jacob G. Foster](https://soc.ucla.edu/person/jacob-foster/); From Thin to Thick: Toward a Politics of Human-Compatible AI. Public Culture 1 September 2023; 35 (3 (101)): 417–430. doi: [https://doi.org/10.1215/08992363-10742593](https://doi.org/10.1215/08992363-10742593)

The distinction between “thick” and “thin” modes of involving communities around (data and) AI is useful. “Thin” involvement skims off surface-level instincts and data from frictionless transactions, while “thick” involvement demands thoughtful, complex, nuanced and stretching engagement. In reality we need both.

<!--more-->

## Thin engagement

I got to [Foster’s paper](https://doi.org/10.1215/08992363-10742593), quoted above, because I was searching for something that was mentioned in a [recent Ezra Klein show](https://www.nytimes.com/2025/11/07/opinion/ezra-klein-podcast-election.html), about seeing that people are “thick” (in the sense of layered and complicated, rather than stupid) and the way polling “thins” them, or surfaces only particular facets:


> **Klein:** I’ve been having these conversations with the political scientist [Henry Farrell](https://sais.jhu.edu/users/hfarrel1), who I think is really brilliant. Something he has been talking about in terms of representation is just recognizing that people in the sociological sense of the term are very thick and complicated. And what you are trying to do is find ways to take them in that thick complexity. And what the internet and much of modern society does — what polling does, too, by the way — is it thins them.
> 
> Now something like polling is better than nothing —
> 
> **Retica:** Maybe.
> 
> **Klein:** It is.
> 
> **Retica:** All right.
> 
> **Klein:** Because the thing that you and I both see happen is that in its absence —
> 
> **Retica:** People just make [expletive] up.
> 
> **Klein:** People make [expletive] up. But they also convinced themselves that what is around them is how everybody feels.
> 
> And polling, when done well, is a way of disciplining at least some of your intuitions. But it does collapse people down to their answers to questions they actually may not have overly strong feelings on.
> 
> So the question of: How do you have the complexity of people contained inside your relationships to them? Well, you have to be in relationship to them.

As Klein says, “thin” approaches to engagement around data and AI have their place. A point we made in [Our Health Data Stories](/resources/our-health-data-stories) is that when people make choices about technology, such as choosing whether or not to use ChatGPT or agreeing to the terms and conditions on a new app, they aren’t thinking deeply about the wider implications of those choices. (We shouldn’t blame people for this, nor should we kid ourselves that anyone is likely to suddenly become much more thoughtful about their day-to-day technology choices if we just educated them or presented them better.) “Thin” polling and attitudes research can tap into what people’s instinctive [“System 1” (thinking fast)](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow) responses are likely to be.

These “thin” responses aren’t things people have thought through or had tested and refined through argument and debate, so they are the most amenable to influence, both positive and negative. Look at how quickly the [support for digital ID](https://www.independent.co.uk/news/uk/home-news/support-keir-starmer-government-policy-prime-minister-britons-b2837422.html) collapsed after its announcement, and the flurry of speculation – and sometimes conspiracy theories – about what it would entail. Or consider the [reduction in abusive language in tweets](https://techcrunch.com/2021/05/05/twitter-rolls-out-improved-reply-prompts-to-cut-down-on-harmful-tweets/) that Twitter (RIP) achieved just by asking users to confirm they wanted to post their draft.

Understanding people in “thin” ways is useful as a reality check, so that you can meet people where they are. It doesn’t tell you where they could be or even where they want to be.

It’s easy to see how polling is “thin” engagement, but I would say the same of many kinds of market research, and even user research. When the purpose of engagement is to monitor, measure, and extract responses which may or may not be fed into the design of a system (whether policy or technology) by those who are actually in control of the system, it is “thin” engagement.


## Thick engagement

The mark of “thick” engagement is that it builds a strong relationship. Not a relationship that’s built around gaslighting and abuse. Nor one that’s built around sycophancy and indulgence. But one that enables constructive challenge and disagreement; that stretches us in ways that drive learning and growth; that sets healthy boundaries and promotes autonomy; that is demanding and rewarding.

“Thick” engagement around data and AI recognises the politics inherent in them – that we are, together, constructing (imperfect) ways forward through sometimes uncomfortable dialogue. This is what Adam Kahane, in his book [“Collaborating with the Enemy”](https://sobrief.com/books/collaborating-with-the-enemy) terms “stretch collaboration”. It is not easy, but that’s part of the point. In their work exploring an [approach to AI governance founded on care ethics](https://6pack.care/manifesto/), Audrey Tang describes this as “exercising our ‘civic muscle.’” (There are parallels here with the idea that AI assistants are bringing about a “[stupidogenic society](https://substack.nomoremarking.com/p/are-we-living-in-a-stupidogenic-society)”: one in which things become so easy that our brains are not stretched, and so atrophy.)

If we are to have a thriving democracy, we need to have opportunities to practice, and that goes both for people and communities affected by technology, and the organisations that are in charge of it. We need to provide room for debate and challenge, not just reaction. I don’t just think of this as exercising civic muscles: I think of it as political activation. We have to empower and equip people to continue to try to change things they think should be changed, including through information about their rights and democratic processes, as well as connections with others who share their values and perspectives.


## Bringing them together

“Thick” approaches really require small groups of people, such as the patients at a single hospital or job hunters at a single job centre, because it’s in the personal connections that the relationship building happens. “Thin” engagement approaches are easier on both organisations and participants, but they also scale, and that can be vital for legitimacy.

This is why I’m so interested in distributed models, in which there are multiple small, probably local dialogues that together inform and feed into the bigger picture. [Tang describes](https://6pack.care/manifesto/) using these in a national Alignment Assembly around the regulation of deepfake investment scams:

> More recently, we applied this at scale to the plague of deepfake investment scams, often featuring figures like Jensen Huang (likely generated using NVIDIA GPUs). People wanted action, but we did not want censorship.
> 
> We convened a national Alignment Assembly with the Collective Intelligence Project. We used a diamond-shaped approach:
> 
>  * **Discovery (Open):** We sent 200,000 SMS messages (a “democracy lottery”). Everyone, even those not selected, could use Polis to set the agenda. This broad participation contributes significantly to legitimacy.
>  * **Definition (Protected):** We invited 450 demographically representative citizens to deliberate in groups of ten.
> 
> AI assistants provided real-time transcripts and facilitation. Language models (tools similar to Google Jigsaw’s Sensemaker) synthesized proposals in real-time—ideas like requiring digital signatures for ads, making platforms jointly liable for the full amount scammed, or dialing down the network reach (slowing CDN connections) of non-compliant platforms.
> 
> The final package earned over 85 percent cross-partisan support. This rigor is crucial; it functions as a “duck-rabbit”—from one side it looks like a deliberation, from the other it looks like a rigorous poll, providing legitimacy for the legislature.

Our own work on distributed dialogues about [generative AI in education](/ai-in-education/toolkit/) shows another model. Here, teachers are provided with materials for running classes with their students, and then submit the outputs into a central platform for analysis, summarisation, and presentation to decision makers. Tim wrote about other distributed models in his work exploring [options for a global citizen deliberation on AI](/resources/global-deliberation-ai), a crucial feature of which is using local dialogue to catalyse local action.

Both thin and thick modes of engagement have their place. If we just treat public participation in a ‘thin’ way, as a way of extracting information about what people think, we miss what could be an important role in creating connection, prompting action, and shoring up democracy. But people’s actual behaviour with technology isn’t thoughtful or deliberative, and we need to design systems that meet people where they are, not where we’d like them to be. ‘Thin’ approaches can provide a level of scale and legitimacy that ‘thick’ approaches struggle with. We need smart and robust ways of bringing ‘thick’ and ‘thin’ models of engagement together, such as through distributed deliberation, so that we can get the best of both worlds.